{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29afbdf3-5eac-4b30-b83f-7a673807f5db",
   "metadata": {},
   "source": [
    "Well the logistic regression parameter estimation was a doozy. Let's try something more simple for a change. Let's try an algorithm that is not so much grounded in theory but is very flexible, universal (can be used for value and class prediction) and fast to compute: K-nearest neaighbours aka KNN.\n",
    "\n",
    "The idea of KNN is that similar objects are close to each other in the feature space. By using the distance metric, we can calculate the distances between any two objects and determine which objects are closest to a given object. In the classification task, the distance metric used is typically Euclidean distance, although other metrics such as Manhattan distance or cosine similarity can also be used.\n",
    "\n",
    "The algorithm steps go like this:\n",
    "\n",
    "1. Take the point we want to predict ($X_p$, $y_p$) and calculate its distance  to all other points $ d(X_p;X_i) \\forall i$\n",
    "2. Sort the distances in from smallest to largest, and use $K$ points to calculate $y_p$, we can use various metrics, but mean/median for continous variables, and mode for categorical are generally used\n",
    "3. Assess the fit of $y_p$ the algorithm success mostly relies only one parameter $K$. We can change the change $K$ to arrive at the best fit. \n",
    "\n",
    "Of course there can be more improvements to the model such as changing the distance metric, scaling the input values $X_i$ and dealing with outliers. But let's just to the basics for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7e106-8d1c-4c46-bb4b-4b0c457aee57",
   "metadata": {},
   "source": [
    "Let's start with euclidean distance function to calculate  \n",
    "$\\Sigma_i^n (X_{n1}-X_{n2})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759a63c7-4547-4d71-a643-f6c4c6375803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#calculate distance function\n",
    "def calc_euclidean_distance(p1, p2):\n",
    "    return(np.sqrt(np.sum((p1-p2)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fd1e8-9fdc-4840-8147-5a718e2d8253",
   "metadata": {},
   "source": [
    "Then add just look for the smallest $K$ distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a84cacc-e067-436c-a50a-902bec36a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, y_train, x_pred, k):\n",
    "    y_preds = np.array([])\n",
    "    for j in range(0, x_new.shape[0]):\n",
    "        distances = np.array([])\n",
    "        for i in range(0, X_train.shape[0]):\n",
    "            distances=np.append(distances, calc_euclidean_distance(x_new[j], X_train.iloc[i].values))\n",
    "            idx = np.argsort(distances)[:k] \n",
    "            y_pred = mode(y_train[idx])[0]\n",
    "        y_preds=np.append(y_preds,y_pred)\n",
    "        \n",
    "    return(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935c76c-6c12-40d4-9e0b-19d7d3431c01",
   "metadata": {},
   "source": [
    "Let's do a small example for the famous Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94e95c9-5cd9-468d-8d9c-c4ec6cff9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from scipy.stats import mode\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df.target\n",
    "\n",
    "#print(df.tail())\n",
    "\n",
    "#now the create some value we'll want to predixt\n",
    "x_new1=[5, 3, 1.9, 0.5]\n",
    "x_new2=[ 6.0, 2.8, 5.1, 2.1   ]\n",
    "x_new = np.vstack([x_new1, x_new2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77670b6a-d3cb-4145-bd58-fa93d375778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X, y, x_new1, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81756cd-14e1-4e72-86aa-28d276c06b98",
   "metadata": {},
   "source": [
    "And we're set. Since the algorithm was not very hard let's put in a class to appear more classy. We'll just initialize the KNN with some $K$ and add functions we already defined, but adjust `predict` to work with pandas arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3627d32-b7a9-4de6-9754-af578546fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn_model:\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "    def calc_euclidean_distance(p1, p2):\n",
    "        return(np.sqrt(np.sum((p1-p2)**2)))    \n",
    "    def predict(self, X_train, y_train, x_pred):\n",
    "        y_preds = np.array([])\n",
    "        for j, rj in x_pred.iterrows():\n",
    "            distances = np.array([])\n",
    "            for i,r in X_train.iterrows():\n",
    "                distances=np.append(distances, calc_euclidean_distance(rj, r))\n",
    "                idx = np.argsort(distances)[:self.K] \n",
    "                y_pred = mode(y_train[idx])[0]\n",
    "            y_preds=np.append(y_preds, y_pred)\n",
    "\n",
    "        return(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00010df-b33d-4d51-a8e1-fb38681f6c3a",
   "metadata": {},
   "source": [
    "The model predict out imaginary iris plant to be in the 0th class so the funcitons seem to work, but let's see how it would perform in a realistic setting: let's do a simple train/test split and train see how the model performs for various $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2668d12-cf51-4b35-b396-daea67e68332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d14ed9-9703-4bc9-8006-745747141a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    44\n",
       "0    38\n",
       "1    38\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see if our sample is biased, we're in luck becase it is very nicely balances.\n",
    "#we can use simple accuracy as measure of success\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6b9310ab-c38c-488a-b871-4cfddcccd90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=list()\n",
    "for k in range(2, 10):\n",
    "    model2 = knn_model(K=k)\n",
    "    result = model2.predict(X_train, y_train.reset_index(drop=True), X_test)\n",
    "    acc=np.mean(y_test == result)\n",
    "    accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e35b764-32df-45fc-a44d-1b89b8259f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.9666666666666667]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f44db28-1980-4bcc-8146-a2ff67b00337",
   "metadata": {},
   "source": [
    "Seems to be very accurate, either way, probably the problem is not that hard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
