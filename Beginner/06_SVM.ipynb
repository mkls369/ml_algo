{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019015d-b6e7-45bb-9c81-6497343a2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: loss function derivation needs an update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df89c07-24f6-40e4-8327-787fc8a7b68e",
   "metadata": {},
   "source": [
    "Have you ever wondered if linear regression could help us clasify data rather than predict a continouous outcome? SVMs can do just that and so much more. So let's dive in. The idea of an SVM is to separate points by drawing a line between them so that the line would be as far as possible from the closest points it is trying to separate. In a more genral case (higher dimension) the line becomes a hyperplane and it also incorparate a kernel, but more on that later. Let's stick with the basic case for now. A line function is defined like this:  \n",
    "$$y=a+bx$$\n",
    "and this is how hyperplanes are usually written down:  \n",
    "$$0=b+w^Tx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9850f-a5fd-4da8-ab43-f7292cd37934",
   "metadata": {},
   "source": [
    "The hyperplane acts as separator that can between negative and positive values of $b+w^Tx$\n",
    "\n",
    "Let's say we have hyperplance goint through points $x_1$ and $x_2$ respectively and we want to draw a hyperplane equality distnant to both of those hyperplance. Let's say that the hyperplanes satistfy these equalities:\n",
    "\n",
    "$$b+w^Tx_1=1$$\n",
    "$$b+w^Tx_2=-1$$\n",
    "\n",
    "now subtract and get: \n",
    "$$w^T(x1-x2)=2 $$\n",
    "Finally to get an expression of $x_1-x_2$ we need to divide by the $w^T$ \"inverse\" i.e. its norm $||w||$ so we get:\n",
    "$$(x1-x2)=\\frac{2}{||w||} $$\n",
    "\n",
    "Remember that we wanted to maximize the distance, so this is the distance we want to maximize:\n",
    "$$max\\frac{2}{||w||}$$\n",
    "subjet to \n",
    "\n",
    "\\begin{equation}\n",
    "  y_n =\n",
    "    \\begin{cases}\n",
    "      if +1, & b+w^Tx_1\\ge 1\\\\\n",
    "      if -1, & b+w^Tx_2\\lt-1\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "which can be convieniently be rewritten as:\n",
    "$$y_n(w^Tx+b)\\ge1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a24f61-944b-46cf-aba4-0b75a2d6530a",
   "metadata": {},
   "source": [
    "A few more things are left to be done, usually we try to minimuze a function, though we have a maximization exercise so let's change that. first of all we can get rid of the constant because it doesn't change anything:\n",
    "$$max\\frac{1}{||w||} = min||w||$$\n",
    "\n",
    "Often L2 norm is chosen so we minimize $$min\\frac{1}{2}||w||^2 $$\n",
    "\n",
    "But this is a very strict criterion and will not allow us to misclassify any point of data which will lead to there being no solutions unless there points are linearly seperable. What we can do is introduce an error term for misclassified points:\n",
    "\n",
    "$ C_i \\sum_{i=1}^n\\xi_i$, where $\\xi_i = max[0, 1-y_n(w^Tx+b)]$ this expression is called the hinge loss function $f(x)=max[0, 1-r]$. This means that the loss will be zero (but never negative) of if certain conditions are met and will aquire some value if some other condition is met. What are those conditions in our case?\n",
    "\n",
    "$$r= 1-y_n(w^Tx + b)$$\n",
    "\n",
    "Let's say our true value is in the positive hyperplane $y_n=+1$ and our model has classified it to be in the negative hyperplane $(w^Tx + b) < 0$ the expression $y_n(w^Tx + b)$ is thus negative and increases the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00025c3e-9f29-47b2-8edb-02d9c5394810",
   "metadata": {},
   "source": [
    "Let's write the full loss function \n",
    "$$  minL(w)= \\frac{1}{2}||w||^2 + C_i\\sum_i^n max[0, 1-y_n(w^Tx+b)]$$\n",
    "and it's derivative:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d57bc-e041-4c48-822e-e7dee1eb4485",
   "metadata": {},
   "source": [
    "\n",
    "$$\\nabla_wL= w + C_i \\sum -y_nx_i\\mathbb{1}_{\\{y_nw^Tx<1\\}}$$\n",
    "and we're good to go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b01b76f-3721-4a20-804a-091db7f628c4",
   "metadata": {},
   "source": [
    "In other words when the loss gradient is\n",
    "\n",
    "\\begin{equation}\n",
    "  \\nabla_wL =\n",
    "    \\begin{cases}\n",
    "      \\textrm{if correct clasification}, & w\\\\\n",
    "      \\textrm{if incorrect clasification}, &  w-(y_nx_i)\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "014b1c13-7cac-412f-9bd7-891740868084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "# iris = datasets.load_breast_cancer()\n",
    "\n",
    "# #prepping the input data, let's leave the\n",
    "# df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "# df['target'] = iris.target\n",
    "# X = df.drop('target', axis=1)\n",
    "# y = df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "210549fd-4300-4327-a5d1-cf1335a7c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=200, # 1000 observations \n",
    "    n_features=4, # 5 total features\n",
    "    n_informative=2, # 3 'useful' features\n",
    "    n_classes=2, # binary target/label \n",
    "    random_state=369 # if you want the same results as mine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "074f4282-d71c-4bc2-bf9a-ccdefc601258",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "iters=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66ce697e-068d-402c-84bb-3caa776b9518",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "y_ = np.where(y_np <= 0, -1, 1)\n",
    "w = np.zeros(n_features)\n",
    "b = 0\n",
    "lr=0.0001\n",
    "n_iters=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9add6a7f-ff0c-4464-b3f9-a46fbeac0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(n_iters):\n",
    "    for idx, x_i in enumerate(X):\n",
    "        condition = y_[idx] * (np.dot(x_i, w) - b) >= 1\n",
    "        if condition:\n",
    "            w -= lr * (lr * w)\n",
    "        else:\n",
    "            w -= lr * (lr * w - np.dot(x_i, y_[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39a7d1e6-366c-4ba7-88a8-416973157b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00047254, -0.18054646,  0.33415795,  0.07907543])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ec8f225-05ba-4765-ac7d-0315bfead87b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (30,) and (1,) not aligned: 30 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (30,) and (1,) not aligned: 30 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.dot(x_i, y_[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "20e2e42e-0d40-4fc0-85af-7eaf44ddddcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17229999999999734"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6be3a22c-2b46-43dc-804e-e28cad0ce3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx = np.dot(X, w) - b\n",
    "pr = np.sign(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b57284-7271-42f3-af1a-7c6c16399814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
