{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56753e1c-7881-4262-933c-b26858c2c77b",
   "metadata": {},
   "source": [
    "The decision tree is a very intuitive way of representing hierarchical (i.e. nonlinear) relationships. The general idea of the of the algorithm is: split the observations along the predictors in such a way that that the splitted observations as dissimilar as possible along the targets. In other words we have to find a way to discriminate by X in order to separate Y as much as possible.\n",
    "\n",
    "Short glossary:\n",
    "Root node — node at the top of the tree. \n",
    "Decision nodes — nodes where the variables are evaluated. These nodes have arrows pointing to them and away from them\n",
    "Leaf nodes — final node where the prediction is made\n",
    "\n",
    "What we will need to implement the algorithm:\n",
    "1. Choose an improvement metric (it is usually called node purness) for the alogrithm, the common are: information gain, gain ratio, or Gini index.\n",
    "2. Split the data to maximize the improvement metric. \n",
    "3. Stop when the end node is \"pure\" or a stopping condition is reach. Common stopping conditions are: tree depth,  minmum sample size in a given leaf.\n",
    "\n",
    "Step 2 is reiterated until step 3 is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702bfd3-dd92-440e-bcea-ba48a29e7be5",
   "metadata": {},
   "source": [
    "Lets's use entropy and information gain as our metric. Entropy is defined as:  \n",
    "$H(X) = \\mathop{\\mathbb{E}}[-log_2(p(x))] = -\\Sigma_nlog_2(p_i(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52581f9-a6d1-4d71-b93a-4459e3743461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def calc_entropy(arr):\n",
    "    freq = np.bincount(arr)\n",
    "    prob = freq / len(arr)\n",
    "    \n",
    "    entropy = 0\n",
    "    for p in prob:\n",
    "        if p > 0:\n",
    "            entropy += p * np.log2(p)\n",
    "    return -entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820eedf2-999b-456f-89a0-6a9735c843af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.11354948"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1+1.8/100) * (1+6.20/100) * (1+3.00/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0a1944-1717-4ac0-8594-589866ee191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: -0.0\n"
     ]
    }
   ],
   "source": [
    "#lets do some caluclations with this metric\n",
    "#pure array = no entropy\n",
    "pure_array = [0, 0, 0, 0]\n",
    "print(f'Entropy: {np.round(calc_entropy(pure_array), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24215399-5bd7-47f4-9665-e98a24c4f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 2.0\n"
     ]
    }
   ],
   "source": [
    "#impure array = max entropy\n",
    "impure_array = [1, 2, 3, 0]\n",
    "print(f'Entropy: {np.round(calc_entropy(impure_array), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468fa9a5-dfbb-49d6-a9ed-356d6dc26f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 1.0\n",
      "Entropy: 0.811\n"
     ]
    }
   ],
   "source": [
    "#mixed array = some entropy\n",
    "mixed_array1 = [1, 1, 0, 0]\n",
    "print(f'Entropy: {np.round(calc_entropy(mixed_array1), 3)}')\n",
    "\n",
    "mixed_array2 = [1, 0, 0, 0]\n",
    "print(f'Entropy: {np.round(calc_entropy(mixed_array2), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac3099-af6b-421d-b79d-0ec07f346161",
   "metadata": {},
   "source": [
    "The algorithm should strive to decrease entropy as much as possible and we can measure this by calculating information gain $IG(T, a) = H(T) - H(T|a)$  \n",
    "Let's just call $H(T)$ the entropy of parent node and  H(T|a) the average of child nodes after the split. And thus without delving a lot into the intricacies of information gain we have a measure of improvement - the more the entropy falls after each split the better the split is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afdd1897-6ce8-4156-896b-85ec413290b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_information_gain(parent, child1, child2):\n",
    "    weight1 = len(child1) / len(parent)\n",
    "    weight2 = len(child2) / len(parent)\n",
    "    \n",
    "    ig = calc_entropy(parent) - (weight1 * calc_entropy(child1) + weight2 * calc_entropy(child2))\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f8c9a5-0e93-4493-b68e-cf455756b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's calculate a very simple case\n",
    "#split this parent into these children\n",
    "parent1 = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "child1 =  [0, 0, 0, 1, 0]\n",
    "child2 =  [1, 1, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74737019-d21b-46bb-b494-2d82ed99d427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2780719051126377"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_information_gain(parent1, child1, child2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1188265d-9923-4dd5-8b78-5ec4177c6e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7219280948873623\n",
      "0.7219280948873623\n"
     ]
    }
   ],
   "source": [
    "#let's check our work\n",
    "print(calc_entropy(parent1))\n",
    "print(calc_entropy(child1))\n",
    "print(calc_entropy(child2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdf56ddc-c9af-460e-bd2d-4f701a82c2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2780719051126377"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_entropy(parent1)  - (calc_entropy(child1) + calc_entropy(child2))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26f0ce-d110-44ed-a322-dfa303b03289",
   "metadata": {},
   "source": [
    "Ok now we need to get use the information gain to find the best split for the data. Let's start with a simple case and load the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb63b4c3-77ed-42be-a225-bcc8fafe3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from scipy.stats import mode\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#prepping the input data, let's leave the\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b680e8-7713-4bac-bcfc-97c142b2dd8a",
   "metadata": {},
   "source": [
    "Let's inspct the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b079309b-841b-41c1-97d5-a5bd41bc01a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "160d4d0c-f822-4967-9896-885b2cb76d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c7899-a3b0-41b8-ade8-796b085c9373",
   "metadata": {},
   "source": [
    "Now what we need to do is to split the $y$ by each predictor ($n_pred$) and by each unique value of the predictor (we will call this $threshold$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38fd14f3-36f8-4113-b88b-e4d4085ee277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np=X.to_numpy()\n",
    "y_np=y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "246f7ec9-4667-4428-af83-dfed0d0c29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "    Helper class which implements a single tree node.\n",
    "    '''\n",
    "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.data_left = data_left\n",
    "        self.data_right = data_right\n",
    "        self.gain = gain\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57def00b-6bba-4755-af3a-f450a808d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(X, y):\n",
    "    best_split = {}\n",
    "    best_info_gain = -1\n",
    "    n_rows, n_cols = X.shape\n",
    "\n",
    "    df = np.concatenate((X, y.reshape(1, -1).T), axis=1)\n",
    "    # For every dataset feature\n",
    "    for f_idx in range(n_cols):\n",
    "        X_curr = X[:, f_idx]\n",
    "        # For every unique value of that feature\n",
    "        for threshold in np.unique(X_curr):\n",
    "            # Construct a dataset and split it to the left and right parts\n",
    "            # Left part includes records lower or equal to the threshold\n",
    "            # Right part includes records higher than the threshold\n",
    "            \n",
    "            df_left = np.array([row for row in df if row[f_idx] <= threshold])\n",
    "            df_right = np.array([row for row in df if row[f_idx] > threshold])\n",
    "\n",
    "            # Do the calculation only if there's data in both subsets\n",
    "            if len(df_left) > 0 and len(df_right) > 0:\n",
    "                # Obtain the value of the target variable for subsets\n",
    "                y = df[:, -1].astype('int64')\n",
    "                y_left = df_left[:, -1].astype('int64')\n",
    "                y_right = df_right[:, -1].astype('int64')\n",
    "\n",
    "                # Caclulate the information gain and save the split parameters\n",
    "                # if the current split if better then the previous best\n",
    "                #import ipdb; ipdb.set_trace()\n",
    "                gain = calc_information_gain(y, y_left, y_right)\n",
    "                if gain > best_info_gain:\n",
    "                    best_split = {\n",
    "                        'predictor_i': f_idx,\n",
    "                        'threshold': threshold,\n",
    "                        'data_left': df_left,\n",
    "                        'data_right': df_right,\n",
    "                        'gain': gain\n",
    "                    }\n",
    "                    best_info_gain = gain\n",
    "    return(best_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb0320ec-f3c3-4e22-a075-bb731e7303e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=get_best_split(X_np, y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e0e9c4bc-3c7d-4e66-8e99-2e8f3245f34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af8969a8-7a19-417c-87ba-e8b25c46422c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544894"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's get the first split\n",
    "split_1 = get_best_split(X_np, y_np)\n",
    "split_1['gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "284c98b3-8a1f-4e11-b894-09d5caf062bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b302dff-2a24-4fb8-9be2-27344ce0fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#now lets split it again\n",
    "#splitting child1 is pointless because we alrady have min entropy\n",
    "split_1_1 = get_best_split(split_1['child1'][:,:-1], split_1['child1'][:,[-1]])\n",
    "print(split_1_1['gain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff25929a-4d89-4d14-8055-b3cd44a6c2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6901603707546748\n"
     ]
    }
   ],
   "source": [
    "split_1_2 = get_best_split(split_1['child2'][:,:-1], split_1['child2'][:,[-1]])\n",
    "print(split_1_2['gain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55db008c-56c3-4053-9d39-ab7374fa19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_1_2_1 = get_best_split(split_1_2['child2'][:,:-1], split_1_2['child2'][:,[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ecba565-4cfd-46b0-9d02-4ad0da8d8204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09120811177442958"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negative gain was achieved, splitting here is pointless\n",
    "split_1_2_1['gain']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05d409-0941-42e8-a1de-810ab74b50b1",
   "metadata": {},
   "source": [
    "We could on and on but we already see that no gain was achieved in the last split, so we need some stopping condition. Usually we use these\n",
    "1. Positive information gain\n",
    "2. Max depth of the tree\n",
    "3. Minimum number of observation in a split\n",
    "\n",
    "Ok we have the core of the algorithm now we need it to bring it together. We need to apply `get_best_split` until any of the above conditoins are met for that we will use recursion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3956569-cb6e-4596-b5c8-d09af402ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as st\n",
    "def grow_tree(X, y, depth=0, min_samples_split=2, max_depth=3):\n",
    "    n_rows, n_cols = X.shape\n",
    "\n",
    "    # Check to see if a node should be leaf node\n",
    "    if n_rows >= min_samples_split and depth <= max_depth:\n",
    "        # Get the best split\n",
    "        best = get_best_split(X, y)\n",
    "        #import ipdb;ipdb.set_trace()\n",
    "        # If the split isn't pure\n",
    "        if best['gain'] > 0:\n",
    "            child1 = grow_tree(\n",
    "                X=best['data_left'][:, :-1], \n",
    "                y=best['data_left'][:, -1], \n",
    "                depth=depth + 1\n",
    "            )\n",
    "            child2 = grow_tree(\n",
    "                X=best['data_right'][:, :-1], \n",
    "                y=best['data_right'][:, -1], \n",
    "                depth=depth + 1\n",
    "            )\n",
    "\n",
    "            node = Node(\n",
    "                feature=best['predictor_i'], \n",
    "                threshold=best['threshold'], \n",
    "                data_left=child1, \n",
    "                data_right=child2, \n",
    "                gain=best['gain']\n",
    "            )\n",
    "\n",
    "            return node\n",
    "    #Leaf node - predict mode\n",
    "    return Node(value=st.mode(y)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccaea23c-827f-4876-a4db-704565179f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_tree(tree):\n",
    "    if tree:\n",
    "        print(vars(tree))\n",
    "        traverse_tree(tree.data_left)\n",
    "        traverse_tree(tree.data_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b866ff39-7002-495c-bc43-70f045408918",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree=grow_tree(X_np, y_np, depth = 0, min_samples_split=5, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91bc813c-0481-40e2-9e4c-68e07498a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature': 2, 'threshold': 1.9, 'data_left': <__main__.Node object at 0x7f98e028ad70>, 'data_right': <__main__.Node object at 0x7f98e03e81c0>, 'gain': 0.9182958340544894, 'value': None}\n",
      "{'feature': None, 'threshold': None, 'data_left': None, 'data_right': None, 'gain': None, 'value': 0.0}\n",
      "{'feature': 3, 'threshold': 1.7, 'data_left': <__main__.Node object at 0x7f98e0454580>, 'data_right': <__main__.Node object at 0x7f98e03ea560>, 'gain': 0.6901603707546748, 'value': None}\n",
      "{'feature': 2, 'threshold': 4.9, 'data_left': <__main__.Node object at 0x7f98e025a0e0>, 'data_right': <__main__.Node object at 0x7f98e0455240>, 'gain': 0.21317043093799645, 'value': None}\n",
      "{'feature': 3, 'threshold': 1.6, 'data_left': <__main__.Node object at 0x7f99b057afb0>, 'data_right': <__main__.Node object at 0x7f99b0578d30>, 'gain': 0.1460942501201363, 'value': None}\n",
      "{'feature': None, 'threshold': None, 'data_left': None, 'data_right': None, 'gain': None, 'value': 1.0}\n",
      "{'feature': None, 'threshold': None, 'data_left': None, 'data_right': None, 'gain': None, 'value': 2.0}\n",
      "{'feature': 3, 'threshold': 1.5, 'data_left': <__main__.Node object at 0x7f98e025b400>, 'data_right': <__main__.Node object at 0x7f98e0455db0>, 'gain': 0.4591479170272448, 'value': None}\n",
      "{'feature': None, 'threshold': None, 'data_left': None, 'data_right': None, 'gain': None, 'value': 2.0}\n",
      "{'feature': None, 'threshold': None, 'data_left': None, 'data_right': None, 'gain': None, 'value': 1.0}\n",
      "{'feature': 2, 'threshold': 4.8, 'data_left': <__main__.Node object at 0x7f98e03ebdf0>, 'data_right': <__main__.Node object at 0x7f98e03e8370>, 'gain': 0.09120811177442958, 'value': None}\n",
      "{'feature': 0, 'threshold': 5.9, 'data_left': <__main__.Node object at 0x7f98e03e9cf0>, 'data_right': <__main__.Node object at 0x7f98e03eb2b0>, 'gain': 0.9182958340544896, 'value': None}\n",
      "{'feature': None, 'threshold': None, 'data_left': None, 'data_right': None, 'gain': None, 'value': 1.0}\n",
      "{'feature': None, 'threshold': None, 'data_left': None, 'data_right': None, 'gain': None, 'value': 2.0}\n",
      "{'feature': None, 'threshold': None, 'data_left': None, 'data_right': None, 'gain': None, 'value': 2.0}\n"
     ]
    }
   ],
   "source": [
    "traverse_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fed80b6e-2891-460c-aaaf-0e88293eb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_value(x, tree):\n",
    "    if tree.value != None:\n",
    "        return(tree.value)\n",
    "    feature_value = x[tree.feature]\n",
    "    #Go down left child\n",
    "    if feature_value <= tree.threshold:\n",
    "        return predict_value(x=x, tree=tree.data_left)\n",
    "\n",
    "    #Go down right child\n",
    "    if feature_value > tree.threshold:\n",
    "        return predict_value(x=x, tree=tree.data_right) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d13aa847-a906-493c-8062-c80f73075449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_value(X_np[0], my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2207aa4e-216f-4e5f-b99e-914a2a3e44d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b47cefc1-520b-497b-8613-c95c4b4491a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[predict_value(X_np[i], my_tree) for i in range(0, X_np.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16bdfdb8-d312-4f6e-a804-e44fd65a04cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y.values.flatten()==preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5552385-da03-46fd-b38d-547ad1569c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
